{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Dataset Sint√©tico SBA M√©xico - An√°lisis y Uso\n",
    "\n",
    "Este notebook demuestra c√≥mo usar el dataset sint√©tico de cr√©ditos PyME M√©xico,\n",
    "equivalente al dataset SBA de Estados Unidos.\n",
    "\n",
    "**Contenido:**\n",
    "1. Carga y exploraci√≥n del dataset\n",
    "2. Mapeo de variables SBA ‚Üí M√©xico\n",
    "3. An√°lisis exploratorio\n",
    "4. Ejemplo de modelo de predicci√≥n de default\n",
    "5. C√≥mo adaptar tu modelo existente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer√≠as\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:,.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset\n",
    "df = pd.read_csv('sba_mexico_sintetico.csv', parse_dates=['ApprovalDate', 'DisbursementDate', 'ChgOffDate'])\n",
    "\n",
    "print(f\"Dimensiones del dataset: {df.shape}\")\n",
    "print(f\"\\nColumnas disponibles:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vista general\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠sticas descriptivas\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mapeo de Variables SBA ‚Üî M√©xico\n",
    "\n",
    "| Variable SBA Original | Variable M√©xico | Notas |\n",
    "|----------------------|-----------------|-------|\n",
    "| NAICS | SCIAN | Compatible a 2 d√≠gitos |\n",
    "| State | State | C√≥digos de estados mexicanos |\n",
    "| SBA_Appv | NAFIN_Appv | Garant√≠a de Nacional Financiera |\n",
    "| LowDoc | - | No hay programa equivalente directo |\n",
    "| Default | Default | Misma definici√≥n |\n",
    "| ChgOffPrinGr | ChgOffPrinGr | En MXN en lugar de USD |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario de sectores SCIAN\n",
    "SECTORES_SCIAN = {\n",
    "    '11': 'Agricultura, ganader√≠a, pesca',\n",
    "    '21': 'Miner√≠a',\n",
    "    '22': 'Generaci√≥n de energ√≠a',\n",
    "    '23': 'Construcci√≥n',\n",
    "    '31': 'Manufactura - Alimentos',\n",
    "    '32': 'Manufactura - Textil/Qu√≠mica',\n",
    "    '33': 'Manufactura - Met√°lica/Maquinaria',\n",
    "    '43': 'Comercio al por mayor',\n",
    "    '46': 'Comercio al por menor',\n",
    "    '48': 'Transporte',\n",
    "    '51': 'Informaci√≥n en medios',\n",
    "    '52': 'Servicios financieros',\n",
    "    '53': 'Servicios inmobiliarios',\n",
    "    '54': 'Servicios profesionales',\n",
    "    '56': 'Servicios de apoyo',\n",
    "    '61': 'Servicios educativos',\n",
    "    '62': 'Servicios de salud',\n",
    "    '71': 'Esparcimiento/Cultura',\n",
    "    '72': 'Alojamiento/Alimentos',\n",
    "    '81': 'Otros servicios',\n",
    "}\n",
    "\n",
    "df['Sector_Nombre'] = df['SCIAN'].map(SECTORES_SCIAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. An√°lisis Exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuci√≥n de la variable objetivo\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Default rate\n",
    "default_counts = df['Default'].value_counts()\n",
    "axes[0].pie(default_counts, labels=['No Default', 'Default'], autopct='%1.1f%%', \n",
    "            colors=['#2ecc71', '#e74c3c'], explode=[0, 0.05])\n",
    "axes[0].set_title('Distribuci√≥n de Defaults')\n",
    "\n",
    "# Default rate por a√±o\n",
    "default_by_year = df.groupby('ApprovalFY')['Default'].mean() * 100\n",
    "axes[1].bar(default_by_year.index, default_by_year.values, color='steelblue')\n",
    "axes[1].axhline(y=df['Default'].mean()*100, color='red', linestyle='--', label='Promedio')\n",
    "axes[1].set_xlabel('A√±o de Aprobaci√≥n')\n",
    "axes[1].set_ylabel('Tasa de Default (%)')\n",
    "axes[1].set_title('Tasa de Default por A√±o')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default por sector\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "default_by_sector = df.groupby('Sector_Nombre').agg({\n",
    "    'Default': 'mean',\n",
    "    'LoanNr_ChkDgt': 'count'\n",
    "}).sort_values('Default', ascending=True)\n",
    "\n",
    "colors = ['#e74c3c' if x > 0.10 else '#f39c12' if x > 0.07 else '#2ecc71' \n",
    "          for x in default_by_sector['Default']]\n",
    "\n",
    "bars = ax.barh(default_by_sector.index, default_by_sector['Default'] * 100, color=colors)\n",
    "ax.axvline(x=df['Default'].mean()*100, color='black', linestyle='--', linewidth=2, label='Promedio')\n",
    "ax.set_xlabel('Tasa de Default (%)')\n",
    "ax.set_title('Tasa de Default por Sector SCIAN')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuci√≥n de montos\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histograma de montos (log scale)\n",
    "axes[0].hist(df['GrAppv']/1e6, bins=50, color='steelblue', edgecolor='white', alpha=0.7)\n",
    "axes[0].set_xlabel('Monto Aprobado (Millones MXN)')\n",
    "axes[0].set_ylabel('Frecuencia')\n",
    "axes[0].set_title('Distribuci√≥n de Montos Aprobados')\n",
    "axes[0].set_xlim(0, 5)  # Limitar a 5 millones para mejor visualizaci√≥n\n",
    "\n",
    "# Boxplot por tama√±o de empresa\n",
    "df['Tamano'] = pd.cut(df['NoEmp'], bins=[0, 10, 50, 250, 1000], \n",
    "                      labels=['Micro', 'Peque√±a', 'Mediana', 'Grande'])\n",
    "\n",
    "df.boxplot(column='GrAppv', by='Tamano', ax=axes[1])\n",
    "axes[1].set_ylabel('Monto Aprobado (MXN)')\n",
    "axes[1].set_title('Monto por Tama√±o de Empresa')\n",
    "axes[1].ticklabel_format(style='plain', axis='y')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapa de calor: Default por Estado\n",
    "default_by_state = df.groupby('State')['Default'].agg(['mean', 'count'])\n",
    "default_by_state.columns = ['Tasa_Default', 'Num_Prestamos']\n",
    "default_by_state = default_by_state.sort_values('Num_Prestamos', ascending=False).head(15)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.bar(default_by_state.index, default_by_state['Tasa_Default'] * 100, \n",
    "              color='steelblue', edgecolor='white')\n",
    "ax.axhline(y=df['Default'].mean()*100, color='red', linestyle='--', label='Promedio Nacional')\n",
    "ax.set_xlabel('Estado')\n",
    "ax.set_ylabel('Tasa de Default (%)')\n",
    "ax.set_title('Tasa de Default por Estado (Top 15 por volumen)')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preparaci√≥n de Datos para Modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar features para el modelo (similar a tu modelo SBA)\n",
    "features = [\n",
    "    'GrAppv',           # Monto aprobado\n",
    "    'NAFIN_Appv',       # Monto garantizado (equivalente a SBA_Appv)\n",
    "    'Term',             # Plazo\n",
    "    'NoEmp',            # N√∫mero de empleados\n",
    "    'NewExist',         # Nuevo/Existente\n",
    "    'UrbanRural',       # Urbano/Rural\n",
    "    'RealEstate',       # Garant√≠a inmobiliaria\n",
    "    'Portion',          # Proporci√≥n garantizada\n",
    "    'Recession',        # Indicador de recesi√≥n\n",
    "    'New',              # Variable binaria nuevo\n",
    "]\n",
    "\n",
    "# Variables categ√≥ricas a codificar\n",
    "categorical_features = ['State', 'SCIAN', 'Bank']\n",
    "\n",
    "# Crear copia para modelado\n",
    "df_model = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar variables categ√≥ricas\n",
    "label_encoders = {}\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df_model[col + '_encoded'] = le.fit_transform(df_model[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "    features.append(col + '_encoded')\n",
    "\n",
    "# Convertir RevLineCr a num√©rico\n",
    "df_model['RevLineCr_num'] = (df_model['RevLineCr'] == 'Y').astype(int)\n",
    "features.append('RevLineCr_num')\n",
    "\n",
    "print(f\"Features seleccionados: {len(features)}\")\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar X e y\n",
    "X = df_model[features].copy()\n",
    "y = df_model['Default'].copy()\n",
    "\n",
    "# Verificar valores faltantes\n",
    "print(\"Valores faltantes por columna:\")\n",
    "print(X.isnull().sum())\n",
    "\n",
    "# Dividir en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set: {len(X_train):,} registros\")\n",
    "print(f\"Test set: {len(X_test):,} registros\")\n",
    "print(f\"\\nTasa de default en train: {y_train.mean()*100:.2f}%\")\n",
    "print(f\"Tasa de default en test: {y_test.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Entrenamiento de Modelo de Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_prob_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Random Forest - Resultados en Test Set\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(f\"\\nAUC-ROC: {roc_auc_score(y_test, y_prob_rf):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting (alternativa)\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "y_prob_gb = gb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Gradient Boosting - Resultados en Test Set\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "print(f\"\\nAUC-ROC: {roc_auc_score(y_test, y_prob_gb):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar curvas ROC\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Curvas ROC\n",
    "for name, y_prob, color in [('Random Forest', y_prob_rf, 'blue'), \n",
    "                             ('Gradient Boosting', y_prob_gb, 'green')]:\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    axes[0].plot(fpr, tpr, color=color, label=f'{name} (AUC = {auc:.4f})')\n",
    "\n",
    "axes[0].plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].set_title('Curvas ROC')\n",
    "axes[0].legend()\n",
    "\n",
    "# Feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=True)\n",
    "\n",
    "axes[1].barh(importance_df['Feature'], importance_df['Importance'], color='steelblue')\n",
    "axes[1].set_xlabel('Importancia')\n",
    "axes[1].set_title('Importancia de Variables (Random Forest)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predicci√≥n de P√©rdida (ChgOffPrinGr)\n",
    "\n",
    "Para predecir la p√©rdida monetaria, usamos un modelo de dos etapas:\n",
    "1. Predecir probabilidad de default\n",
    "2. Predecir p√©rdida condicional al default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para los defaults, entrenar modelo de regresi√≥n para ChgOffPrinGr\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Filtrar solo defaults\n",
    "df_defaults = df_model[df_model['Default'] == 1].copy()\n",
    "print(f\"Registros con default: {len(df_defaults):,}\")\n",
    "\n",
    "# Features para regresi√≥n\n",
    "X_loss = df_defaults[features]\n",
    "y_loss = df_defaults['ChgOffPrinGr']\n",
    "\n",
    "# Train/test split\n",
    "X_train_loss, X_test_loss, y_train_loss, y_test_loss = train_test_split(\n",
    "    X_loss, y_loss, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Entrenar modelo de regresi√≥n\n",
    "loss_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "loss_model.fit(X_train_loss, y_train_loss)\n",
    "\n",
    "# Evaluar\n",
    "y_pred_loss = loss_model.predict(X_test_loss)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "print(f\"MAE: ${mean_absolute_error(y_test_loss, y_pred_loss):,.2f} MXN\")\n",
    "print(f\"R¬≤: {r2_score(y_test_loss, y_pred_loss):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar predicciones vs reales\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "ax.scatter(y_test_loss/1e6, y_pred_loss/1e6, alpha=0.3, color='steelblue')\n",
    "ax.plot([0, y_test_loss.max()/1e6], [0, y_test_loss.max()/1e6], 'r--', label='Perfecta')\n",
    "ax.set_xlabel('P√©rdida Real (Millones MXN)')\n",
    "ax.set_ylabel('P√©rdida Predicha (Millones MXN)')\n",
    "ax.set_title('Predicci√≥n de P√©rdida (ChgOffPrinGr)')\n",
    "ax.legend()\n",
    "ax.set_xlim(0, 2)\n",
    "ax.set_ylim(0, 2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. C√≥mo Adaptar tu Modelo SBA Existente\n",
    "\n",
    "Si ya tienes un modelo entrenado con datos SBA de EE.UU., puedes adaptarlo as√≠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para renombrar columnas de M√©xico a formato SBA\n",
    "def convertir_a_formato_sba(df_mexico):\n",
    "    \"\"\"\n",
    "    Convierte el dataset M√©xico al formato exacto del dataset SBA\n",
    "    para compatibilidad con modelos existentes.\n",
    "    \"\"\"\n",
    "    df_sba = df_mexico.copy()\n",
    "    \n",
    "    # Renombrar columnas principales\n",
    "    renombres = {\n",
    "        'SCIAN': 'NAICS',           # Sistema de clasificaci√≥n compatible\n",
    "        'NAFIN_Appv': 'SBA_Appv',   # Garant√≠a gubernamental\n",
    "    }\n",
    "    df_sba = df_sba.rename(columns=renombres)\n",
    "    \n",
    "    # Agregar columna LowDoc (no existe equivalente, ponemos N)\n",
    "    df_sba['LowDoc'] = 'N'\n",
    "    \n",
    "    return df_sba\n",
    "\n",
    "# Ejemplo de uso\n",
    "df_sba_format = convertir_a_formato_sba(df)\n",
    "print(\"Columnas en formato SBA:\")\n",
    "print([c for c in df_sba_format.columns if c in ['NAICS', 'SBA_Appv', 'LowDoc', 'GrAppv', 'Default']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para transfer learning (fine-tuning)\n",
    "def fine_tune_modelo_sba(modelo_sba_original, X_mexico, y_mexico, epochs=5):\n",
    "    \"\"\"\n",
    "    Ejemplo conceptual de c√≥mo hacer fine-tuning de un modelo SBA\n",
    "    con datos mexicanos.\n",
    "    \n",
    "    Para modelos scikit-learn: usar warm_start=True\n",
    "    Para redes neuronales: entrenar capas finales con learning rate bajo\n",
    "    \"\"\"\n",
    "    # Para Random Forest con warm_start\n",
    "    modelo_mexico = modelo_sba_original\n",
    "    modelo_mexico.n_estimators += 50  # Agregar m√°s √°rboles\n",
    "    modelo_mexico.fit(X_mexico, y_mexico)\n",
    "    \n",
    "    return modelo_mexico\n",
    "\n",
    "print(\"Para hacer transfer learning:\")\n",
    "print(\"1. Carga tu modelo SBA entrenado\")\n",
    "print(\"2. Convierte datos M√©xico al formato SBA\")\n",
    "print(\"3. Haz fine-tuning con los datos mexicanos\")\n",
    "print(\"4. Eval√∫a en datos de prueba mexicanos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exportar Modelo para Producci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Guardar modelos\n",
    "joblib.dump(rf_model, 'modelo_default_rf_mexico.pkl')\n",
    "joblib.dump(loss_model, 'modelo_perdida_mexico.pkl')\n",
    "joblib.dump(label_encoders, 'label_encoders_mexico.pkl')\n",
    "\n",
    "print(\"Modelos guardados:\")\n",
    "print(\"  - modelo_default_rf_mexico.pkl\")\n",
    "print(\"  - modelo_perdida_mexico.pkl\")\n",
    "print(\"  - label_encoders_mexico.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n de predicci√≥n completa\n",
    "def predecir_riesgo_credito(datos_prestamo, modelo_default, modelo_perdida, encoders):\n",
    "    \"\"\"\n",
    "    Predice probabilidad de default y p√©rdida esperada.\n",
    "    \n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    datos_prestamo : dict\n",
    "        Diccionario con caracter√≠sticas del pr√©stamo\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    dict con prob_default, perdida_esperada, recomendacion\n",
    "    \"\"\"\n",
    "    # Preparar datos\n",
    "    df_input = pd.DataFrame([datos_prestamo])\n",
    "    \n",
    "    # Codificar categ√≥ricas\n",
    "    for col, encoder in encoders.items():\n",
    "        if col in df_input.columns:\n",
    "            df_input[col + '_encoded'] = encoder.transform(df_input[col].astype(str))\n",
    "    \n",
    "    # Predecir default\n",
    "    prob_default = modelo_default.predict_proba(df_input[features])[:, 1][0]\n",
    "    \n",
    "    # Predecir p√©rdida condicional\n",
    "    perdida_condicional = modelo_perdida.predict(df_input[features])[0]\n",
    "    \n",
    "    # P√©rdida esperada = P(default) * P√©rdida|default\n",
    "    perdida_esperada = prob_default * perdida_condicional\n",
    "    \n",
    "    # Recomendaci√≥n\n",
    "    if prob_default < 0.05:\n",
    "        recomendacion = 'APROBAR - Riesgo bajo'\n",
    "    elif prob_default < 0.15:\n",
    "        recomendacion = 'REVISAR - Riesgo moderado'\n",
    "    else:\n",
    "        recomendacion = 'RECHAZAR - Riesgo alto'\n",
    "    \n",
    "    return {\n",
    "        'probabilidad_default': prob_default,\n",
    "        'perdida_condicional': perdida_condicional,\n",
    "        'perdida_esperada': perdida_esperada,\n",
    "        'recomendacion': recomendacion\n",
    "    }\n",
    "\n",
    "# Ejemplo de uso\n",
    "ejemplo_prestamo = {\n",
    "    'GrAppv': 500000,\n",
    "    'NAFIN_Appv': 300000,\n",
    "    'Term': 36,\n",
    "    'NoEmp': 5,\n",
    "    'NewExist': 2,\n",
    "    'UrbanRural': 1,\n",
    "    'RealEstate': 0,\n",
    "    'Portion': 0.6,\n",
    "    'Recession': 0,\n",
    "    'New': 0,\n",
    "    'State': 'JAL',\n",
    "    'SCIAN': '46',\n",
    "    'Bank': 'BBVA M√©xico',\n",
    "    'RevLineCr': 'N'\n",
    "}\n",
    "\n",
    "print(\"\\nEjemplo de predicci√≥n:\")\n",
    "print(f\"Pr√©stamo: ${ejemplo_prestamo['GrAppv']:,} MXN\")\n",
    "# resultado = predecir_riesgo_credito(ejemplo_prestamo, rf_model, loss_model, label_encoders)\n",
    "# print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Resumen y Pr√≥ximos Pasos\n",
    "\n",
    "### Dataset Generado:\n",
    "- **50,000 registros** de pr√©stamos PyME sint√©ticos\n",
    "- **32 variables** compatibles con estructura SBA\n",
    "- **Calibrado** con datos reales de CNBV, INEGI y Banxico\n",
    "- **Tasa de default realista**: ~10% (dentro del rango hist√≥rico mexicano)\n",
    "\n",
    "### C√≥mo mejorar el dataset:\n",
    "\n",
    "1. **Agregar datos reales**: Si consigues acceso a microdatos de ENAFIN a trav√©s de solicitud formal a INEGI\n",
    "\n",
    "2. **Calibrar tasas de default por sector**: Usar reportes trimestrales de CNBV sobre IMOR\n",
    "\n",
    "3. **Incluir variables macroecon√≥micas**: Tasa de inter√©s Banxico, inflaci√≥n, tipo de cambio\n",
    "\n",
    "4. **Expandir a LATAM**: Agregar datos de Colombia (SFC), Brasil (BCB), Chile (CMF)\n",
    "\n",
    "### Fuentes de datos adicionales:\n",
    "- CNBV Portafolio de informaci√≥n: https://portafoliodeinformacion.cnbv.gob.mx/\n",
    "- Banxico Sistema de Informaci√≥n Econ√≥mica: https://www.banxico.org.mx/SieInternet/\n",
    "- INEGI Censos Econ√≥micos: https://www.inegi.org.mx/programas/ce/2024/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
